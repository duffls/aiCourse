{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd796e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x) \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "\n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext() # 다음 인덱스로 이동 \n",
    "\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1e4ed",
   "metadata": {},
   "source": [
    "# 1 hidden layer( 6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "153d6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate: \n",
    "    def __init__(self, gate_name, xdata, tdata): # xdata, tdata, W, b 초기화\n",
    "        self.name = gate_name \n",
    "        self.xdata = xdata.reshape(4,2) # 입력 데이터 초기화\n",
    "        self.tdata = tdata.reshape(4,1) # 정답 데이터 초기화\n",
    "\n",
    "        # 입력층 노드 2 개, 은닉층 노드 6 개. 은닉층 개수는 적당한 값으로 정핚다.\n",
    "        self.W2 = np.random.rand(2,6) \n",
    "        self.b2 = np.random.rand(6)\n",
    "        # 은닉층 노드 6 개, 출력층 노드 1 개\n",
    "        self.W3 = np.random.rand(6,1)\n",
    "        self.b3 = np.random.rand(1)\n",
    "        # 학습률 learning rate 초기화.\n",
    "        self.learning_rate = 1e-2 \n",
    "\n",
    "    def feed_forward(self): # 피드포워드 수행하며 손실함수 값 계산\n",
    "        delta = 1e-7 # log 무핚대 발산 방지\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2 # 은닉층 선형회귀 값\n",
    "        a2 = sigmoid(z2) # 은닉층 출력\n",
    "        z3 = np.dot(a2, self.W3) + self.b3 # 출력층 선형회귀 값\n",
    "        y = a3 = sigmoid(z3) # 출력층 출력\n",
    "        return -np.sum(self.tdata*np.log(y+delta)+(1-self.tdata)*np.log((1 - y)+delta))\n",
    "\n",
    "    def loss_val(self): # 손실함수 값 계산\n",
    "        delta = 1e-7 # log 무핚대 발산 방지\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2 # 은닉층 선형회귀 값\n",
    "        a2 = sigmoid(z2) # 은닉층 출력\n",
    "        z3 = np.dot(a2, self.W3) + self.b3 # 출력층 선형회귀 값\n",
    "        y = a3 = sigmoid(z3) # 출력층 출력\n",
    "        return -np.sum(self.tdata*np.log(y+delta)+(1-self.tdata)*np.log((1 - y)+delta))\n",
    "\n",
    "    def train(self ): # 경사하강법 이용하여 W, b 업데이트\n",
    "        f = lambda x : self.feed_forward() \n",
    "        print(\"Initial loss value = \", self.loss_val())\n",
    "        for step in range(10001): # 경사하강법을 이용해서 W2, W3 와 바이어스 b2, b3 를 업데이트\n",
    "            self.W2 -= self.learning_rate * numerical_derivative(f, self.W2) \n",
    "            self.b2 -= self.learning_rate * numerical_derivative(f, self.b2) \n",
    "            self.W3 -= self.learning_rate * numerical_derivative(f, self.W3) \n",
    "            self.b3 -= self.learning_rate * numerical_derivative(f, self.b3) \n",
    "            if (step % 1000 == 0):\n",
    "                print(\"step = \", step, \"loss value = \", self.loss_val()) \n",
    "\n",
    "    def predict(self, input_data): # 미래 값 예측\n",
    "        self.xdata = input_data\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2 # 은닉층 선형회귀 값\n",
    "        a2 = sigmoid(z2) # 은닉층 출력\n",
    "        z3 = np.dot(a2, self.W3) + self.b3 # 출력층 선형회귀 값\n",
    "        y = a3 = sigmoid(z3) # 출력층 출력\n",
    "\n",
    "        if y > 0.5:\n",
    "            result = 1 \n",
    "        else:\n",
    "            result = 0 \n",
    "\n",
    "        return y, result \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9ecc3",
   "metadata": {},
   "source": [
    "# 2 hidden layer ( 4, 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "744755b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate: \n",
    "    def __init__(self, gate_name, xdata, tdata): # xdata, tdata, W, b 초기화\n",
    "        self.name = gate_name \n",
    "        self.xdata = xdata.reshape(4,2) # 입력 데이터 초기화\n",
    "        self.tdata = tdata.reshape(4,1) # 정답 데이터 초기화\n",
    "\n",
    "        # 입력층 노드 2 개, 은닉층 노드 6 개. 은닉층 개수는 적당한 값으로 정핚다.\n",
    "        self.W2 = np.random.rand(2,4) \n",
    "        self.b2 = np.random.rand(4)\n",
    "        # 은닉층1 노드 4 개, 출력층 노드 1 개\n",
    "        self.W3 = np.random.rand(4,3)\n",
    "        self.b3 = np.random.rand(3)\n",
    "        # 은닉층 노드 3 개, 출력층 노드 1 개\n",
    "        self.W4 = np.random.rand(3,1)\n",
    "        self.b4 = np.random.rand(1)\n",
    "        # 학습률 learning rate 초기화.\n",
    "        self.learning_rate = 1e-2 \n",
    "\n",
    "    def feed_forward(self): # 피드포워드 수행하며 손실함수 값 계산\n",
    "        delta = 1e-7 # log 무핚대 발산 방지\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2 # 은닉층 선형회귀 값\n",
    "        a2 = sigmoid(z2) # 은닉층 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3 # 은닉층 선형회귀 값\n",
    "        a3 = sigmoid(z3) # 은닉층 출력\n",
    "        \n",
    "        z4 = np.dot(a3, self.W4) + self.b4 # 출력층 선형회귀 값\n",
    "        y = a4 = sigmoid(z4) # 출력층 출력\n",
    "        \n",
    "        return -np.sum(self.tdata*np.log(y+delta)+(1-self.tdata)*np.log((1 - y)+delta))\n",
    "\n",
    "    def loss_val(self): # 손실함수 값 계산\n",
    "        delta = 1e-7 # log 무핚대 발산 방지\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2 # 은닉층 선형회귀 값\n",
    "        a2 = sigmoid(z2) # 은닉층 출력\n",
    "\n",
    "        z3 = np.dot(a2, self.W3) + self.b3 # 은닉층 선형회귀 값\n",
    "        a3 = sigmoid(z3) # 은닉층 출력\n",
    "\n",
    "        z4 = np.dot(a3, self.W4) + self.b4 # 출력층 선형회귀 값\n",
    "        y = a4 = sigmoid(z4) # 출력층 출력\n",
    "        \n",
    "        return -np.sum(self.tdata*np.log(y+delta)+(1-self.tdata)*np.log((1 - y)+delta))\n",
    "\n",
    "    def train(self ): # 경사하강법 이용하여 W, b 업데이트\n",
    "        f = lambda x : self.feed_forward() \n",
    "        print(\"Initial loss value = \", self.loss_val())\n",
    "        for step in range(40001): # 경사하강법을 이용해서 W2, W3 와 바이어스 b2, b3 를 업데이트\n",
    "            self.W2 -= self.learning_rate * numerical_derivative(f, self.W2) \n",
    "            self.b2 -= self.learning_rate * numerical_derivative(f, self.b2) \n",
    "            self.W3 -= self.learning_rate * numerical_derivative(f, self.W3) \n",
    "            self.b3 -= self.learning_rate * numerical_derivative(f, self.b3) \n",
    "            self.W4 -= self.learning_rate * numerical_derivative(f, self.W4) \n",
    "            self.b4 -= self.learning_rate * numerical_derivative(f, self.b4) \n",
    "            if (step % 1000 == 0):\n",
    "                print(\"step = \", step, \"loss value = \", self.loss_val()) \n",
    "\n",
    "    def predict(self, input_data): # 미래 값 예측\n",
    "        self.xdata = input_data\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2 # 은닉층 선형회귀 값\n",
    "        a2 = sigmoid(z2) # 은닉층 출력\n",
    "\n",
    "        z3 = np.dot(a2, self.W3) + self.b3 # 은닉층 선형회귀 값\n",
    "        a3 = sigmoid(z3) # 은닉층 출력\n",
    "        \n",
    "        z4 = np.dot(a3, self.W4) + self.b4 # 출력층 선형회귀 값\n",
    "        y = a4 = sigmoid(z4) # 출력층 출력\n",
    "\n",
    "        if y > 0.5:\n",
    "            result = 1 \n",
    "        else:\n",
    "            result = 0 \n",
    "\n",
    "        return y, result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "20e01286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value =  4.432652067229332\n",
      "step =  0 loss value =  4.358529232140617\n",
      "step =  1000 loss value =  2.77321153116539\n",
      "step =  2000 loss value =  2.773022035627201\n",
      "step =  3000 loss value =  2.772844601755283\n",
      "step =  4000 loss value =  2.7726750437563585\n",
      "step =  5000 loss value =  2.772509625003823\n",
      "step =  6000 loss value =  2.772344864995805\n",
      "step =  7000 loss value =  2.77217737381374\n",
      "step =  8000 loss value =  2.7720036977181817\n",
      "step =  9000 loss value =  2.771820161523719\n",
      "step =  10000 loss value =  2.771622693143847\n",
      "step =  11000 loss value =  2.771406613171667\n",
      "step =  12000 loss value =  2.7711663670075772\n",
      "step =  13000 loss value =  2.770895167594427\n",
      "step =  14000 loss value =  2.770584500863434\n",
      "step =  15000 loss value =  2.770223419091061\n",
      "step =  16000 loss value =  2.769797501258387\n",
      "step =  17000 loss value =  2.76928727841619\n",
      "step =  18000 loss value =  2.7686657748254953\n",
      "step =  19000 loss value =  2.767894538177505\n",
      "step =  20000 loss value =  2.766916986621544\n",
      "step =  21000 loss value =  2.765646774549251\n",
      "step =  22000 loss value =  2.763946425303912\n",
      "step =  23000 loss value =  2.7615857885716295\n",
      "step =  24000 loss value =  2.7581557346068104\n",
      "step =  25000 loss value =  2.7528745795705136\n",
      "step =  26000 loss value =  2.7441152613997017\n",
      "step =  27000 loss value =  2.728149632975519\n",
      "step =  28000 loss value =  2.695671807129993\n",
      "step =  29000 loss value =  2.6235855131870074\n",
      "step =  30000 loss value =  2.4729834709008287\n",
      "step =  31000 loss value =  2.2530413045050786\n",
      "step =  32000 loss value =  2.020923232607064\n",
      "step =  33000 loss value =  1.6341674381078737\n",
      "step =  34000 loss value =  0.88671179408618\n",
      "step =  35000 loss value =  0.3873695494593212\n",
      "step =  36000 loss value =  0.2035949156306611\n",
      "step =  37000 loss value =  0.12822584766719777\n",
      "step =  38000 loss value =  0.09061807635767838\n",
      "step =  39000 loss value =  0.0689238026754381\n",
      "step =  40000 loss value =  0.055083342622811476\n",
      "[0 0]  =  0\n",
      "[0 1]  =  1\n",
      "[1 0]  =  1\n",
      "[1 1]  =  0\n"
     ]
    }
   ],
   "source": [
    "# XOR 논리 게이트 학습\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ]) # 입력 데이터 생성\n",
    "tdata = np.array([0, 1, 1, 0])\n",
    "xor_obj = LogicGate(\"XOR\", xdata, tdata) # XOR 객체생성\n",
    "xor_obj.train() \n",
    "\n",
    "# XOR 논리 게이트 검증\n",
    "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "for data in test_data:\n",
    "    sigmoid_val, logical_val = xor_obj.predict(data) # 임의 데이터에 대해 결과 예측\n",
    "    print(data, \" = \", logical_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1f03c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def step(x):\n",
    "    return np.array(x > 0, dtype=np.int)\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = step(x)\n",
    "plt.title('Stem Function')\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678d27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac41047e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4178c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e48b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0323d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d734ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a01c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad4f974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616a3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e30a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
