{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b9b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627df7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b06b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN 클래스 정의\n",
    "class NeuralNetwork:\n",
    " # 생성자\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # 각 층의 노드와 학습율 초기화 ①\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        self.learning_rate = learning_rate\n",
    "        # Xavier/He 방법으로 가중치 / 바이이어스 초기화\n",
    "        # 각 층으로 들어오는 입력노드 개수의 제곱근을 사용해 가중치를 초기화하는 방식\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes)/np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes)\n",
    "        \n",
    "        self.W3 = np.random.randn(self.hidden_nodes, self.output_nodes)/np.sqrt(self.hidden_nodes/2)\n",
    "        self.b3 = np.random.rand(self.output_nodes)\n",
    "        \n",
    "        # 출력층 선형회귀 값 z3, 출력값 a3\n",
    "        self.Z3 = np.zeros([1,output_nodes])\n",
    "        self.Z3 = np.zeros([1,output_nodes])\n",
    "        self.A3 = np.zeros([1,output_nodes])\n",
    "\n",
    "        # 은닉층 선형회귀 값 z3, 출력값 a3\n",
    "        self.Z2 = np.zeros([1,hidden_nodes])        \n",
    "        self.A2 = np.zeros([1,hidden_nodes])\n",
    "        \n",
    "        # 입력층 선형회귀 값 z3, 출력값 a3\n",
    "        self.Z1 = np.zeros([1,input_nodes])\n",
    "        self.A1 = np.zeros([1,input_nodes])\n",
    "\n",
    "    def feed_forward(self ):\n",
    "        delta = 1e-7 # log 무핚대 발산 방지\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산\n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        y = self.A3 = sigmoid(self.Z3)\n",
    "        return -np.sum( self.target_data*np.log(y+delta) + (1-self.target_data)*np.log((1 - y)+delta) )\n",
    " \n",
    "    def loss_val(self ): # 손실 값 계산\n",
    "        delta = 1e-7 # log 무핚대 발산 방지\n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산\n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        y = self.A3 = sigmoid(self.Z3)\n",
    "        return -np.sum( self.target_data*np.log(y+delta) + (1-self.target_data)*np.log((1 - y)+delta) )\n",
    " \n",
    "    def train(self, input_data, target_data): # 학습\n",
    "        # 피드 포워드 수행\n",
    "        self.input_data = input_data\n",
    "        self.target_data = target_data\n",
    "        loss_val = self.feed_forward() \n",
    "        \n",
    "        # 출력층 loss 인 loss_3 구함\n",
    "        loss_3 = (self.A3-self.target_data) * self.A3 * (1-self.A3)\n",
    "        \n",
    "        # 출력층 가중치 W3, 출력층 바이어스 b3 업데이트\n",
    "        self.W3 = self.W3 - self.learning_rate * np.dot(self.A2.T, loss_3)\n",
    "        self.b3 = self.b3 - self.learning_rate * loss_3\n",
    "        \n",
    "        # 은닉층 loss 인 loss_2 구함\n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)\n",
    "        \n",
    "        # 은닉층 가중치 W2, 은닉층 바이어스 b2 업데이트\n",
    "        self.W2 = self.W2 - self.learning_rate * np.dot(self.A1.T, loss_2)\n",
    "        self.b2 = self.b2 - self.learning_rate * loss_2\n",
    " \n",
    "    def predict(self, input_data): # 예측\n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        y = A3 = sigmoid(Z3)\n",
    "        \n",
    "        # Categorical일땐 argmax()로 최고 확률의 항목을 리턴\n",
    "        # 0 또는 1 이 아닌 argmax() 를 통해 최대 인덱스를 넘겨주어야 함(원핫인코딩 기법)\n",
    "        #predicted_num = np.argmax(y)\n",
    "        #return predicted_num \n",
    "        \n",
    "        # Binary 일때 0 or 1 리턴\n",
    "        if y > 0.5:\n",
    "            predicted_num = 1 \n",
    "        else:\n",
    "            predicted_num = 0 \n",
    "        return predicted_num \n",
    "\n",
    "    def accuracy(self, test_input_data, test_target_data):\n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        for index in range(len(test_input_data)):\n",
    "            label = int(test_target_data[index])\n",
    "            #data = (test_input_data[index, :] / 255.0 * 0.99) + 0.01\n",
    "            data = test_imout_data[index, :]\n",
    "            \n",
    "            predicted_num = self.predict(np.array(data, ndmin=2)) \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "\n",
    "        print(\"Current Accuracy = \", len(matched_list)/(len(test_input_data)) )\n",
    "        return matched_list, not_matched_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a28069e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'loadtxt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11484/2960887707.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# diabetes.csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../diabetes.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;31m#t_data = data['Outcome']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#df = data[:,:-1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ai_source\\machinelearning\\venv\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'loadtxt'"
     ]
    }
   ],
   "source": [
    "# NeuralNetwork 객체 생성 및 학습 (mnist.csv)\n",
    "# training_data = np.loadtxt('./mnist_train.csv', delimiter=',', dtype=np.float32) \n",
    "# i_nodes = 784 # input nodes 개수\n",
    "# h1_nodes = 100 # hidden nodes 개수.\n",
    "# o_nodes = 10 # output nodes 개수\n",
    "# lr = 0.1 # learning rate\n",
    "# epochs = 1 # 반복횟수\n",
    "\n",
    "# obj = NeuralNetwork (i_nodes, h1_nodes, o_nodes, lr) \n",
    "# for i in range(epochs): \n",
    "#     for step in range(len(training_data)):\n",
    "#         input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01 \n",
    "#         target_data = np.zeros(o_nodes) + 0.01\n",
    "#         target_data[int(training_data[step, 0])] = 0.99\n",
    "#         obj.train(np.array(input_data, ndmin=2), np.array(target_data, ndmin=2))\n",
    "#         if (step % 1000 == 0):\n",
    "#             print(\"epochs = \", i, \", step = \", step, \", loss value = \", obj.loss_val())\n",
    "\n",
    "# diabetes.csv\n",
    "data = np.loadtxt('../diabetes.csv', delimiter=',',  dtype=np.float32, skiprows=1)\n",
    "#t_data = data['Outcome']\n",
    "#df = data[:,:-1]\n",
    "\n",
    "training_data = data[:-100, :]\n",
    "test_data = data[-100:, :]\n",
    "\n",
    "# target_data = data[:-100, -1]\n",
    "# test_target_data = data[-100:, -1]\n",
    "\n",
    "i_nodes = 8\n",
    "h1_nodes = 100\n",
    "o_nodes = 1\n",
    "epochs = 2\n",
    "\n",
    "obj = NeuralNetwork (i_nodes, h1_nodes, o_nodes, lr) \n",
    "for i in range(epochs): \n",
    "    for step in range(len(training_data)):\n",
    "        print(step, len(training_data))\n",
    "        input_data = ((training_data[step, :-1] / 255.0) * 0.99) + 0.01 \n",
    "        target_data = np.zeros(o_nodes) + 0.01\n",
    "        #target_data[int(training_data[step, -1])] = 0.99\n",
    "        target_data = training_data[step, -1]\n",
    "\n",
    "        obj.train(np.array(input_data, ndmin=2), np.array(target_data, ndmin=2))\n",
    "        if (step % 1000 == 0):\n",
    "            print(\"epochs = \", i, \", step = \", step, \", loss value = \", obj.loss_val())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acdacf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "i_nodes = 8\n",
    "h1_nodes = 100\n",
    "o_nodes = 1\n",
    "epochs = 2\n",
    "\n",
    "df = pd.read_csv('../diabetes.csv')\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "df2 = mm.fit_transform(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2[:,:-1], df2[:,-1], random_state=555)\n",
    "\n",
    "# data = np.loadtxt('../diabetes.csv', delimiter=',',  dtype=np.float32, skiprows=1)\n",
    "# #t_data = data['Outcome']\n",
    "# #df = data[:,:-1]\n",
    "\n",
    "# training_data = data[:-100, :]\n",
    "# test_data = data[-100:, :]\n",
    "\n",
    "# target_data = data[:-100, -1]\n",
    "# test_target_data = data[-100:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1b764ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss value =  0.06038267951263046\n",
      "epochs =  0 , step =  100 , loss value =  0.7020619450405221\n",
      "epochs =  0 , step =  200 , loss value =  0.1768671122625248\n",
      "epochs =  0 , step =  300 , loss value =  0.3389235767601015\n",
      "epochs =  0 , step =  400 , loss value =  1.102201682938971\n",
      "epochs =  0 , step =  500 , loss value =  0.9718387089493098\n",
      "epochs =  1 , step =  0 , loss value =  1.0264207746069824\n",
      "epochs =  1 , step =  100 , loss value =  0.7486671770143576\n",
      "epochs =  1 , step =  200 , loss value =  0.16750106106001567\n",
      "epochs =  1 , step =  300 , loss value =  0.32083511751440147\n",
      "epochs =  1 , step =  400 , loss value =  1.1855990485064896\n",
      "epochs =  1 , step =  500 , loss value =  0.887203554144519\n"
     ]
    }
   ],
   "source": [
    "obj = NeuralNetwork (i_nodes, h1_nodes, o_nodes, lr) \n",
    "\n",
    "for i in range(epochs): \n",
    "    for step in range(len(X_train)):\n",
    "        input_data = X_train[step, :]\n",
    "        target_data = np.array(np.zeros(o_nodes))\n",
    "        target_data[0] = y_train[step]\n",
    "\n",
    "        obj.train(np.array(input_data, ndmin=2), np.array(target_data))\n",
    "        if (step % 100 == 0):\n",
    "            print(\"epochs = \", i, \", step = \", step, \", loss value = \", obj.loss_val())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71a776bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy =  0.0\n"
     ]
    }
   ],
   "source": [
    "(true_list, false_list) = obj.accuracy(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be56d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy =  0.9332\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 검증\n",
    "test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "test_input_data = test_data[ :, 1: ]\n",
    "test_target_data = test_data[ :, 0 ]\n",
    "(true_list, false_list) = obj.accuracy(test_input_data, test_target_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
